{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Founder Rank\n",
    "This notebook implements all ranking workflows. Data pipeline to be added.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "1. Encoding\n",
    "   - Convert founder profiles to numerical values (ordinals) using:\n",
    "     - Configuration mappings from `src.config.Config.MATRIX`\n",
    "     - Profile evaluation via `src.clients.perplexity_client.eval_person`\n",
    "   - Transform ordinals into feature vectors:\n",
    "     - Each ordinal value is converted to one-hot encoding\n",
    "     - All one-hot vectors are concatenated into a single feature vector\n",
    "     - Implementation: `src.processing.transforms.transform`\n",
    "2. Dataset Creation\n",
    "   - Synthetic Data (`src.datagen.datagen.DataGenerator`):\n",
    "     - Generate founder attributes using pdfs defined in `src.config.Config.SYNTH`\n",
    "     - Assign binary success labels based on predefined criteria (exit or Series B)\n",
    "   \n",
    "   - YC Dataset:\n",
    "     - Scraped batches 2012-2021 and top companies via `src.clients.yc_client` and eval exits, funding via `src.clients.perplexity_client.eval_company`.\n",
    "     - Top YC Companies:\n",
    "        - Known to be successful.\n",
    "     - Batches\n",
    "        - YC W/S 21 have targets for now.\n",
    "     - Implementation: `notebooks.live-data.ipynb` & `src.clients.yc_client`\n",
    "3. Split\n",
    "    - Training is synth + some batch data\n",
    "    - Val/Test is top YC and batch\n",
    "\n",
    "### Model \n",
    "\n",
    "1. Architecutre\n",
    "    - Models (`src.models.quadratic`):\n",
    "        - `QuadraticModel`: Learns pairwise feature interactions via W matrix\n",
    "        - `QuadMLP`: tries to capture nonlinearity or higher order (marginal imporvement )\n",
    "            - Quadratic: x^T W x captures explicit pairwise interactions\n",
    "            - MLP: [64] -> LN -> GELU -> D(0.2) -> [32] -> LN -> GELU -> D(0.1) -> [1]\n",
    "    - Confidence scoring:\n",
    "        - Raw score: $f(x)$ = quadratic + mlp terms \n",
    "        - Probability: $P(success | x) = Ïƒ(f(x))$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.clients.perplexity_client import PerplexityClient\n",
    "from src.clients.proxycurl_client import ProxycurlClient\n",
    "from src.config.config import cfg   \n",
    "from src.processing.transforms import ProfileTransforms\n",
    "\n",
    "from src.clients.perplexity_client import PerplexityClient\n",
    "from src.clients.proxycurl_client import ProxycurlClient\n",
    "from src.processing.transforms import ProfileTransforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "MATRIX=cfg.MATRIX\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = ProxycurlClient()\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "founders = pd.read_csv('../data/live/yc/W21.csv')\n",
    "founders = founders[~((founders['exit_value_usd'] == 0) & (founders['total_funding_usd'] == 0))]\n",
    "\n",
    "founders = founders.head(3)\n",
    "\n",
    "linkedin_profiles = []\n",
    "\n",
    "for idx, row in founders.iterrows():\n",
    "    params = {\n",
    "        'linkedin_profile_url': row['LinkedIn'],\n",
    "        'use_cache': 'if-present'\n",
    "    }\n",
    "    \n",
    "    api_key =os.getenv('PROXYCURL_API_KEY')\n",
    "    headers = {'Authorization': 'Bearer ' + api_key}\n",
    "    api_endpoint = 'https://nubela.co/proxycurl/api/v2/linkedin'\n",
    "    params = {\n",
    "        'linkedin_profile_url': row['LinkedIn'],\n",
    "        'use_cache': 'if-present',\n",
    "    }\n",
    "    response = requests.get(api_endpoint,params=params,headers=headers)\n",
    "    linkedin_profiles.append(response.json())\n",
    "    \n",
    "# Convert to DataFrame for easier analysis\n",
    "linkedin_df = pd.DataFrame(linkedin_profiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = ProfileTransforms(data={}, matrix=MATRIX)\n",
    "\n",
    "df = T.transform_person_endpt(profile_list=linkedin_profiles, cutoff_date=2020)\n",
    "T.df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PerplexityClient()\n",
    "df = T.transform(pc, process_profiles=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = T.create_feature_matrix()\n",
    "df[\"feature_vector\"] = list(feature_matrix)\n",
    "\n",
    "df[[\"Name\", \"Current Company\", \"Current Title\", \"Linkedin\", \"feature_vector\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dimensions for each category from MATRIX config\n",
    "dimensions = {}\n",
    "start_idx = 0\n",
    "for cat in cfg.MATRIX:\n",
    "    dim = cfg.MATRIX[cat][\"DIMENSION\"]\n",
    "    dimensions[cat] = (start_idx, start_idx + dim)\n",
    "    start_idx += dim\n",
    "\n",
    "# Extract feature vectors into separate columns\n",
    "feature_vectors = np.array(df[\"feature_vector\"].tolist())\n",
    "\n",
    "# Create new columns for each feature\n",
    "feature_names = []\n",
    "for cat, (start, end) in dimensions.items():\n",
    "    for i in range(end - start):\n",
    "        if cfg.MATRIX[cat][\"DIMENSION\"] == 3:\n",
    "            col_name = f\"{cat}_{i+1}\"\n",
    "        else:\n",
    "            col_name = f\"{cat}_{i}\"\n",
    "        df[col_name] = feature_vectors[:, start + i]\n",
    "        feature_names.append(col_name)\n",
    "\n",
    "# Drop the feature_vector column\n",
    "df = df.drop(\"feature_vector\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.quadratic import QuadMLP \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"../models/founder_rank.pt\"\n",
    "model = QuadMLP(input_dim=26, hidden_dim=64) \n",
    "\n",
    "# Load state dict and handle scaling parameters\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)  # The model class already has quad_scale and mlp_scale defined\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare features\n",
    "X = df[feature_names].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    logits = model(X_tensor)\n",
    "    \n",
    "    temperature = 2.0\n",
    "    scaled_logits = logits / temperature\n",
    "    \n",
    "    probs = torch.sigmoid(scaled_logits).cpu().numpy()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Add predictions to dataframe    \n",
    "df[\"raw_logits\"] = logits.cpu().numpy()\n",
    "df[\"success_probability\"] = probs\n",
    "df[\"predicted_success\"] = preds\n",
    "\n",
    "# Sort by probability to get rankings\n",
    "ranked_founders = df.sort_values(\"success_probability\", ascending=False)\n",
    "print(ranked_founders[[\"Name\", \"Current Company\", \"success_probability\", \"predicted_success\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
