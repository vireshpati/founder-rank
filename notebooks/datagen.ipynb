{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data code, visualizations and some performance analysis on initial weight matrix.\n",
    "\n",
    "**Equation:**  \n",
    "The composite confidence score is defined as:\n",
    "\n",
    "$$\n",
    "y = x^T W^* x + \\alpha\\,\\log(\\text{exit\\_value}+1) + \\beta\\,\\log(\\text{funding\\_amount}+1) + \\epsilon,\n",
    "$$\n",
    "\n",
    " where:\n",
    " - $x$ is the 26-feature one-hot encoded vector (from 8 founder categories),\n",
    "- $W^*$ is a ground-truth symmetric weight matrix,\n",
    "- $\\alpha, \\beta$ are scalars ,\n",
    "- $\\epsilon \\sim \\mathcal{N}(0,\\text{noise\\_std}^2)$.\n",
    "\n",
    "**Funding/Exit Model:**  \n",
    " - A startup receives funding with probability $p_{funding}$. If funded, the funding amount is sampled from \n",
    "    $\\text{Funding} \\sim \\text{LogNormal}(\\mu_{\\text{funding}}, \\sigma_{\\text{funding}})$.\n",
    " - Conditional on funding, an exit occurs with probability $p_{exit}$; if so, the exit value is sampled from:\n",
    "   $\\text{Exit} \\sim \\text{LogNormal}(\\mu_{\\text{exit}}, \\sigma_{\\text{exit}})$.  \n",
    "- Otherwise (or if unfunded), exit = 0.\n",
    "\n",
    "**Success Metric:**  \n",
    "Higher composite scores should correspond to higher funding and exit values.\n",
    "\n",
    "All hyperparameters (for founder traits, funding, exit, target scaling) are defined below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn plotly scipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX = cfg.MATRIX\n",
    "POPULATIONS = cfg.SYNTH['POPULATIONS']\n",
    "alpha = cfg.SYNTH['alpha']\n",
    "beta = cfg.SYNTH['beta']\n",
    "noise_std = cfg.SYNTH['noise_std']\n",
    "\n",
    "def one_hot_encode_column(values, dimension):\n",
    "    if dimension == 3:\n",
    "        indices = values - 1\n",
    "    else:\n",
    "        indices = values\n",
    "    indices = np.clip(indices, 0, dimension - 1)\n",
    "    return np.eye(dimension, dtype=int)[indices]\n",
    "\n",
    "K = sum(cfg['DIMENSION'] for cfg in MATRIX.values())\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target def\n",
    " \n",
    "We want the quadratic form $x^T W x$ approximates a confidence score that is related to exit and funding.\n",
    "$$\n",
    " y = x^T W^* x + \\alpha \\,\\log(\\text{exit\\_value}+1) + \\beta \\,\\log(\\text{funding\\_amount}+1) + \\epsilon\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x^T W^* x$ is the intrinsic score computed using a ground-truth weight matrix $W^*$ (simulating the combined effect of the founderâ€™s features),\n",
    "- The exit and funding components capture external signals of success (using log to compress scales),\n",
    "- $\\alpha, \\beta$ are scalars\n",
    "- $\\epsilon$ is Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ordinal_for_category(cat, sampling_probs):\n",
    "    d = MATRIX[cat]['DIMENSION']\n",
    "    p = sampling_probs[cat]\n",
    "    if d == 3:\n",
    "        return np.random.choice([1,2,3], p=p)\n",
    "    else:\n",
    "        return np.random.choice([0,1,2,3], p=p)\n",
    "\n",
    "def sample_exit_and_funding(\n",
    "    p_fund, mu_fund, sig_fund,\n",
    "    p_exit, mu_exit, sig_exit,\n",
    "):\n",
    "\n",
    "    if np.random.rand() < p_fund:\n",
    "        funding_amt = np.random.lognormal(mu_fund, sig_fund)\n",
    "        if np.random.rand() < p_exit:\n",
    "            exit_val = np.random.lognormal(mu_exit, sig_exit)\n",
    "        else:\n",
    "            exit_val = 0\n",
    "    else:\n",
    "        funding_amt = 0\n",
    "        exit_val = 0\n",
    "    return exit_val, funding_amt\n",
    "\n",
    "def compute_target(x, W_star, pop_cfg):\n",
    "    # x^T W^* x\n",
    "    feature_score = x @ W_star @ x\n",
    "    e_val, f_val  = sample_exit_and_funding(\n",
    "        pop_cfg[\"p_funding\"], pop_cfg[\"mu_funding\"], pop_cfg[\"sigma_funding\"],\n",
    "        pop_cfg[\"p_exit\"],    pop_cfg[\"mu_exit\"],    pop_cfg[\"sigma_exit\"],\n",
    "    )\n",
    "    exit_comp = alpha * np.log(e_val + 1)\n",
    "    fund_comp = beta  * np.log(f_val + 1)\n",
    "    noise_ = np.random.normal(0, noise_std)\n",
    "    return feature_score + exit_comp + fund_comp + noise_, e_val, f_val\n",
    "\n",
    "def generate_subpopulation(num_samples, pop_cfg, W_star):\n",
    "    X_list, y_list, e_list, f_list = [], [], [], []\n",
    "    for _ in range(num_samples):\n",
    "        # Build the 26-d feature vector\n",
    "        x_parts = []\n",
    "        for cat in MATRIX:\n",
    "            val = sample_ordinal_for_category(cat, pop_cfg[\"sampling_probs\"])\n",
    "            oh = one_hot_encode_column(val, MATRIX[cat]['DIMENSION'])\n",
    "            x_parts.append(oh)\n",
    "        x = np.concatenate(x_parts)\n",
    "        \n",
    "        y_val, e_val, f_val = compute_target(x, W_star, pop_cfg)\n",
    "        X_list.append(x)\n",
    "        y_list.append(y_val)\n",
    "        e_list.append(e_val)\n",
    "        f_list.append(f_val)\n",
    "    return np.array(X_list), np.array(y_list), np.array(e_list), np.array(f_list)\n",
    "\n",
    "def generate_synthetic_dataset(total_samples, populations, seed=42):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    K = sum(MATRIX[c]['DIMENSION'] for c in MATRIX)\n",
    "    \n",
    "    # Build W*\n",
    "    W_star = np.zeros((K, K))\n",
    "    start_idx = 0\n",
    "    for cat in MATRIX:\n",
    "        w = MATRIX[cat]['WEIGHT']\n",
    "        dim = MATRIX[cat]['DIMENSION']\n",
    "        end_idx = start_idx + dim\n",
    "        tiers = np.array(list(range(3, 3-dim, -1))[::-1]) * w\n",
    "        W_star[np.arange(start_idx, end_idx),\n",
    "               np.arange(start_idx, end_idx)] = tiers\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    # Add small random noise off-diagonal\n",
    "    noise = np.random.normal(0, 0.005, (K, K))\n",
    "    np.fill_diagonal(noise, 0)\n",
    "    W_star += noise\n",
    "    W_star = 0.5*(W_star + W_star.T)\n",
    "    \n",
    "    X_all, y_all, e_all, f_all = [], [], [], []\n",
    "    labels = []\n",
    "    for pop_name, pop_cfg in populations.items():\n",
    "        n_sub = int(round(pop_cfg[\"fraction\"] * total_samples))\n",
    "        X_sub, y_sub, e_sub, f_sub = generate_subpopulation(n_sub, pop_cfg, W_star)\n",
    "        X_all.append(X_sub)\n",
    "        y_all.append(y_sub)\n",
    "        e_all.append(e_sub)\n",
    "        f_all.append(f_sub)\n",
    "        labels += [pop_name]*n_sub\n",
    "    \n",
    "    X_final = np.vstack(X_all)\n",
    "    y_final = np.concatenate(y_all)\n",
    "    exit_final = np.concatenate(e_all)\n",
    "    fund_final = np.concatenate(f_all)\n",
    "    labels = np.array(labels[:len(y_final)])\n",
    "    \n",
    "    return X_final, y_final, exit_final, fund_final, labels, W_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_slice(category_name):\n",
    "    start = 0\n",
    "    for cat in MATRIX:\n",
    "        d = MATRIX[cat]['DIMENSION']\n",
    "        if cat == category_name:\n",
    "            return slice(start, start+d)\n",
    "        start += d\n",
    "    return slice(0, 0)  # fallback\n",
    "\n",
    "def plot_category_distribution_overall_and_by_pop(X, pop_labels, category_name):\n",
    "    cat_slice = get_category_slice(category_name)\n",
    "    d = MATRIX[category_name]['DIMENSION']\n",
    "    \n",
    "    cat_indices = X[:, cat_slice].argmax(axis=1)  # 0..(d-1)\n",
    "    \n",
    "    counts = np.bincount(cat_indices, minlength=d)\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    bars = plt.bar(range(d), counts, color='cornflowerblue', edgecolor='black')\n",
    "    plt.title(f\"Overall Distribution of {category_name} (tiers=0..{d-1})\", fontsize=14)\n",
    "    plt.xlabel(\"Tier Index\", fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    \n",
    "    # Annotate with counts\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                 f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ------ (B) By-population distribution (percentage) ------\n",
    "    unique_pops = np.unique(pop_labels)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    width = 0.8 / len(unique_pops)\n",
    "    \n",
    "    # For labeling each pop as % within that pop\n",
    "    pop_percentages = {}\n",
    "    for pop_name in unique_pops:\n",
    "        pop_mask = (pop_labels == pop_name)\n",
    "        cat_pop_indices = cat_indices[pop_mask]\n",
    "        ccounts = np.bincount(cat_pop_indices, minlength=d)\n",
    "        pop_percentages[pop_name] = 100.0 * ccounts / ccounts.sum()\n",
    "    \n",
    "    for i, pop_name in enumerate(unique_pops):\n",
    "        pop_mask = (pop_labels == pop_name)\n",
    "        x_positions = np.arange(d) + (i - len(unique_pops)/2)*width + width/2\n",
    "        bars = plt.bar(x_positions, pop_percentages[pop_name], \n",
    "                       width=width, label=f\"{pop_name} (n={pop_mask.sum()})\")\n",
    "        # Annotate with percentages\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 5:  # only label above certain threshold\n",
    "                plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                         f'{height:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.title(f\"{category_name} Tier Distribution by Population (%)\", fontsize=14)\n",
    "    plt.xlabel(\"Tier Index\", fontsize=12)\n",
    "    plt.ylabel(\"Percentage within Population\", fontsize=12)\n",
    "    plt.xticks(np.arange(d), [str(i) for i in range(d)])\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_hist_overall_and_by_pop(values, pop_labels, title, bins=50, log_scale=False):\n",
    "    bins = int(bins)\n",
    "    \n",
    "    if log_scale:\n",
    "        raw_vals = values\n",
    "        plot_vals = np.log1p(values)  # log(1 + x)\n",
    "        xlabel_str = f\"{title} [log(1 + x)]\"\n",
    "    else:\n",
    "        raw_vals = values\n",
    "        plot_vals = values\n",
    "        xlabel_str = title\n",
    "    \n",
    "    plt.figure(figsize=(9,5))\n",
    "    \n",
    "    # Compute bin edges based on the transformed data\n",
    "    min_val, max_val = plot_vals.min(), plot_vals.max()\n",
    "    bin_edges = np.linspace(min_val, max_val, bins)\n",
    "    \n",
    "    n, bin_edges, patches = plt.hist(plot_vals, bins=bin_edges,\n",
    "                                     color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    plt.title(f\"{title} - Overall Distribution\", fontsize=14)\n",
    "    plt.xlabel(xlabel_str, fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    \n",
    "    # Annotate basic stats\n",
    "    stats_text = (f\"Mean: {raw_vals.mean():.2f}\\n\"\n",
    "                  f\"Median: {np.median(raw_vals):.2f}\\n\"\n",
    "                  f\"Std: {raw_vals.std():.2f}\")\n",
    "    plt.annotate(stats_text, xy=(0.70, 0.75), xycoords='axes fraction',\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # (C) By Population - Hist\n",
    "    # -----------------------------------------------------------------------\n",
    "    unique_pops = np.unique(pop_labels)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    \n",
    "    # We'll reuse the same bin_edges from above for consistency.\n",
    "    \n",
    "    # Distinct color palette\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_pops)))\n",
    "    \n",
    "    for i, pop_name in enumerate(unique_pops):\n",
    "        mask = (pop_labels == pop_name)\n",
    "        sub_vals_raw = raw_vals[mask]\n",
    "        sub_vals_log = plot_vals[mask]  # log(1 + x) if log_scale\n",
    "        \n",
    "        label_str = (f\"{pop_name} (n={mask.sum()}, \"\n",
    "                     f\"mean={sub_vals_raw.mean():.2f}, \"\n",
    "                     f\"std={sub_vals_raw.std():.2f})\")\n",
    "        \n",
    "        plt.hist(sub_vals_log, bins=bin_edges, alpha=0.6,\n",
    "                 label=label_str, color=colors[i])\n",
    "    \n",
    "    plt.xlabel(xlabel_str, fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.title(f\"{title} by Population\", fontsize=14)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # (D) By Population - KDE\n",
    "    # -----------------------------------------------------------------------\n",
    "    plt.figure(figsize=(10,6))\n",
    "    \n",
    "    for i, pop_name in enumerate(unique_pops):\n",
    "        mask = (pop_labels == pop_name)\n",
    "        sub_vals_raw = raw_vals[mask]\n",
    "        sub_vals_log = plot_vals[mask]\n",
    "        \n",
    "        if len(sub_vals_log) > 1:\n",
    "            kde = stats.gaussian_kde(sub_vals_log)\n",
    "            x_eval = np.linspace(sub_vals_log.min(), sub_vals_log.max(), 500)\n",
    "            density = kde(x_eval)\n",
    "            \n",
    "            label_str = f\"{pop_name} (mean={sub_vals_raw.mean():.2f})\"\n",
    "            plt.plot(x_eval, density, label=label_str,\n",
    "                     color=colors[i], linewidth=2)\n",
    "    \n",
    "    plt.xlabel(xlabel_str, fontsize=12)\n",
    "    plt.ylabel(\"Density\", fontsize=12)\n",
    "    plt.title(f\"{title} Density by Population (KDE)\", fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_scatter_overall_and_by_pop(xvals, yvals, pop_labels, x_title, y_title, log_y=False):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    unique_pops = np.unique(pop_labels)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_pops)))\n",
    "    \n",
    "    for i, pop_name in enumerate(unique_pops):\n",
    "        mask = (pop_labels == pop_name)\n",
    "        x_pop = xvals[mask]\n",
    "        y_pop = yvals[mask]\n",
    "        \n",
    "        plt.scatter(x_pop, y_pop, alpha=0.5, label=pop_name, color=colors[i])\n",
    "        \n",
    "        # Fit a line in linear or log scale\n",
    "        if len(x_pop) > 3:\n",
    "            if log_y:\n",
    "                log_y_pop = np.log(y_pop)\n",
    "                z = np.polyfit(x_pop, log_y_pop, 1)\n",
    "                p = np.poly1d(z)\n",
    "                x_range = np.linspace(x_pop.min(), x_pop.max(), 50)\n",
    "                plt.plot(x_range, np.exp(p(x_range)), '--', color=colors[i], \n",
    "                         linewidth=2, alpha=0.7)\n",
    "            else:\n",
    "                z = np.polyfit(x_pop, y_pop, 1)\n",
    "                p = np.poly1d(z)\n",
    "                x_range = np.linspace(x_pop.min(), x_pop.max(), 50)\n",
    "                plt.plot(x_range, p(x_range), '--', color=colors[i], \n",
    "                         linewidth=2, alpha=0.7)\n",
    "    \n",
    "    if log_y:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    # (If Score is always >= 0, this is fine; else remove xlim(left=0).)\n",
    "    plt.xlim(left=0)\n",
    "    \n",
    "    plt.title(f\"{x_title} vs. {y_title} by Population\", fontsize=14)\n",
    "    plt.xlabel(x_title, fontsize=12)\n",
    "    plt.ylabel(y_title + (\" [log scale]\" if log_y else \"\"), fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(W_star):\n",
    "    feature_importance = np.sum(np.abs(W_star), axis=0)\n",
    "    \n",
    "    feature_names = []\n",
    "    for cat_name in MATRIX:\n",
    "        dim = MATRIX[cat_name]['DIMENSION']\n",
    "        for i in range(dim):\n",
    "            feature_names.append(f\"{cat_name}_{i}\")\n",
    "    \n",
    "    sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "    sorted_imp = feature_importance[sorted_indices]\n",
    "    sorted_names = [feature_names[i] for i in sorted_indices]\n",
    "    \n",
    "    top_k = min(15, len(sorted_names))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(range(top_k), sorted_imp[:top_k], color='teal')\n",
    "    plt.xticks(range(top_k), sorted_names[:top_k], rotation=45, ha='right')\n",
    "    plt.title('Top Feature Importance (from W*)', fontsize=14)\n",
    "    plt.xlabel('Feature', fontsize=12)\n",
    "    plt.ylabel('Importance Score', fontsize=12)\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                 f\"{height:.2f}\", ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_heatmap(X, y, exit_vals, fund_vals, feature_names=None):\n",
    "    if feature_names is None:\n",
    "        feature_names = []\n",
    "        for cat_name in MATRIX:\n",
    "            d = MATRIX[cat_name]['DIMENSION']\n",
    "            for i in range(d):\n",
    "                feature_names.append(f\"{cat_name}_{i}\")\n",
    "    \n",
    "    data = np.column_stack([X, y, exit_vals, fund_vals])\n",
    "    col_names = feature_names + ['Score', 'Exit', 'Funding']\n",
    "    df = pd.DataFrame(data, columns=col_names)\n",
    "    \n",
    "    corr = df.corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.zeros_like(corr, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    \n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, \n",
    "                annot=True, fmt=\".2f\")\n",
    "    plt.title('Correlation Heatmap: Features & Targets', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show just the target correlations\n",
    "    target_cols = ['Score','Exit','Funding']\n",
    "    target_corr = corr.loc[target_cols, target_cols]\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(target_corr, cmap=cmap, center=0, square=True,\n",
    "                linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt=\".2f\")\n",
    "    plt.title('Correlation among Targets', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_funding_exit_stats(fund_vals, exit_vals, label=\"Overall\"):\n",
    "    # 5NS\n",
    "    df = pd.DataFrame({'Funding': fund_vals, 'Exit': exit_vals})\n",
    "    \n",
    "    print(f\"----- {label} Summary -----\")\n",
    "    print(\"Funding Stats (in $):\")\n",
    "    print(df['Funding'].describe(percentiles=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]))\n",
    "    print(\"\\nExit Stats (in $):\")\n",
    "    print(df['Exit'].describe(percentiles=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "X_syn, y_syn, exit_syn, fund_syn, pop_labels, W_star = generate_synthetic_dataset(N, POPULATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_name in MATRIX.keys():\n",
    "    plot_category_distribution_overall_and_by_pop(X_syn, pop_labels, cat_name)\n",
    "\n",
    "# (B) Score histogram (linear scale)\n",
    "plot_hist_overall_and_by_pop(y_syn, pop_labels, title=\"Composite Score\", bins=50, log_scale=False)\n",
    "\n",
    "# (C) Funding histogram (log scale in the sense log(1 + x) for plotting)\n",
    "plot_hist_overall_and_by_pop(fund_syn, pop_labels, title=\"Funding Amount\", bins=50, log_scale=True)\n",
    "\n",
    "# (D) Exit histogram (log scale in the sense log(1 + x) for plotting)\n",
    "plot_hist_overall_and_by_pop(exit_syn, pop_labels, title=\"Exit Value\", bins=50, log_scale=True)\n",
    "\n",
    "# (E) Scatter: Score vs. Funding\n",
    "plot_scatter_overall_and_by_pop(y_syn, fund_syn, pop_labels, \n",
    "                                x_title=\"Composite Score\", y_title=\"Funding\", log_y=True)\n",
    "\n",
    "# (F) Scatter: Score vs. Exit\n",
    "plot_scatter_overall_and_by_pop(y_syn, exit_syn, pop_labels,\n",
    "                                x_title=\"Composite Score\", y_title=\"Exit\", log_y=True)\n",
    "\n",
    "# (G) Feature importance from W*\n",
    "plot_feature_importance(W_star)\n",
    "\n",
    "# (H) Correlation Heatmap (Features + Score/Exit/Funding)\n",
    "plot_correlation_heatmap(X_syn, y_syn, exit_syn, fund_syn)\n",
    "\n",
    "\n",
    "print_funding_exit_stats(fund_syn, exit_syn, label=\"Overall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "for cat in MATRIX:\n",
    "    dim = MATRIX[cat]['DIMENSION']\n",
    "    for i in range(dim):\n",
    "        feature_names.append(f\"{cat}_{i}\")\n",
    "\n",
    "df = pd.DataFrame(X_syn, columns=feature_names)\n",
    "df[\"target\"] = y_syn\n",
    "\n",
    "\n",
    "df.to_csv(\"../data/synth/encoded_founders_composites.csv\", index=False)\n",
    "# df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
