{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook an entire ranking workflow (no training). Includes:\n",
    "\n",
    "1. Linkedin scraping via proxycurl\n",
    "2. Encoding data into ordinals (sufficient for naive matrix) and a $1\\times26$ feature vector (one hot by ordinal)\n",
    "3. Computing a simple score and prioritizing based on the score (from original matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests pandas python-dotenv openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.config.config import cfg\n",
    "\n",
    "from src.clients.perplexity_client import PerplexityClient\n",
    "from src.clients.proxycurl_client import ProxycurlClient\n",
    "from src.data.transforms import ProfileTransforms\n",
    "from src.utils.model_utils import initialize_weight_matrix, score_feature_matrix\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linkedin Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = ProxycurlClient()\n",
    "\n",
    "N = 1\n",
    "params = {\n",
    "    \"country\": \"US\",\n",
    "    \"education_school_name\": \"Georgia Institute of Technology\",  # can add college of computing, isye, etc. later\n",
    "    \"current_role_title\": 'Founder OR Co-Founder OR \"Founding Engineer\" OR CEO OR CTO OR Stealth',\n",
    "    \"enrich_profiles\": \"enrich\",\n",
    "    \"page_size\": N,\n",
    "    \"use_cache\": \"if-present\",  # should be if-recent for final\n",
    "}\n",
    "\n",
    "# data = px.person_search(params=params, N=N)\n",
    "with open(\"../data/proxycurl/proxy_sample.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Proxycurl data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PerplexityClient()\n",
    "T = ProfileTransforms(data, cfg.MATRIX)\n",
    "\n",
    "df = T.transform(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unranked Founder Data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Configuration\n",
    "\n",
    "Consider [this](https://docs.google.com/document/d/1D7Zjma2FrrnSuoQTMsI0ec_5ENTzjN6wIpKoI4O1ASE/edit?tab=t.0) evaluation matrix. \n",
    "\n",
    "We could consider learning the tiers, but hardcoding it seems fine since we don't have enough data.\n",
    "\n",
    "Here's the current matrix scoring schema:\n",
    "\n",
    "| Category  | Encoding | Example                             | Dimension |\n",
    "|-----------|----------|-------------------------------------|-----------|\n",
    "| Undergrad | One hot  | [Tier 3, Tier 2, Tier 1 (other)]| 3  |\n",
    "| Graduate | One hot | [Tier 3, Tier 2, Tier 1 (other), Fallback/None] | 4|\n",
    "| Previous Exit | One hot | [100m+, 25m-100m, 1-25m, Fallback/None] | 4 |\n",
    "| Previous Founder | One hot | [yes - success, yes, no] | 3 |\n",
    "| Prior Startup Exp | One hot | [early + success, early, no] | 3|\n",
    "| Company as Employee Quality | One hot | [Tier 3, Tier 2, Tier 1 (other)] | 3|\n",
    "| Seniority | One hot | [Tier 3, Tier 2, Tier 1 (other)]| 3|\n",
    "| Expertise | One hot | [Tier 3, Tier 2, Tier 1 (other)]|3|\n",
    "||||26|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal representation\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = T.create_feature_matrix()\n",
    "df[\"feature_vector\"] = list(feature_matrix)\n",
    "\n",
    "df[[\"Name\", \"Current Company\", \"Current Title\", \"Linkedin\", \"feature_vector\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking \n",
    "\n",
    "W : 26x26 \n",
    "\n",
    "feature_matrix : N x 26\n",
    "\n",
    "Compute scores as: $\\mathrm{score_i} = x_i^T(\\frac{(W+W^T)}{2}+\\Epsilon)x_i$ for each row $x_i$\n",
    "\n",
    "Weight matrix initialization: \n",
    "- Diagonal elements are individual contribution of each feature\n",
    "- Off diagonal elements are pairwise interactions between different features. $w_{ij} >0 \\Rightarrow$ having $i,j$ active together increases score more than individual contributions alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = feature_matrix.shape[1]\n",
    "\n",
    "W = initialize_weight_matrix(K, cfg.MATRIX, seed=42, eps=0)\n",
    "\n",
    "df[\"score\"] = score_feature_matrix(feature_matrix, W)\n",
    "\n",
    "results = df.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "# print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
